# -*- coding: utf-8 -*-
"""Heart Disease Prediction- Satadru.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SA3QvKXQZhBKDcPEDlR-XIx_xh_ujFTB
"""

#EDA
import pandas as pd
import numpy as np

#Visualisation
import seaborn as sns
import matplotlib.pyplot as plt
from xgboost import plot_tree

#Model Preparation & Prediction
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier

#Model Evaluation
from sklearn import metrics
from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix

#Hyperparameter Tuning
from sklearn.model_selection import GridSearchCV

df = pd.read_csv("//content//heart.csv")

"""# Dataset Context

This data set dates from *1988* and consists of *four* databases: Cleveland, Hungary, Switzerland, and Long Beach V. It contains **76** attributes, including the predicted attribute, but all published experiments refer to using a subset of **14** of them.

**NOTE:** The **"target"** field refers to *the presence of heart disease in the patient*. It is integer valued **0** = *no disease* and **1** = *disease*.

## Attribute Information

1. **age**

2. **sex** = = 1: male; 0: female

3. **cp** = chest pain type (4 values)

4. **trestbps** =  resting blood pressure

5. **chol** = serum cholestoral in mg/dl

6. **fbs** = fasting blood sugar > 120 mg/dl

7. **restecg** = resting electrocardiographic results (values 0,1,2)

8. **thalach** = maximum heart rate achieved

9. **exang** = exercise induced angina

10. **oldpeak** = ST depression induced by exercise relative to rest

11. **slope** = the slope of the peak exercise ST segment

12. **ca** = number of major vessels (0-3) colored by flourosopy

13. **thal** = 0: normal; 1: fixed defect; 2: reversable defect.

The names and social security numbers of the patients were recently removed from the database, replaced with dummy values.
"""

df.head()

df.shape

"""## Exploratory Data Analysis"""

df.info()

df.describe().transpose()

"""### Outlier Handling"""

def outlier_detector(data, thresh=3):
    outliers = []
    mean = np.mean(data)
    sd = np.std(data)
    for i in data:
        z_score = (i - mean) / sd
        if np.abs(z_score) > thresh:
            outliers.append(i)
    return outliers

cols = df.columns.to_list()

figure = plt.figure(figsize=(15, 8))

for i, j in enumerate(cols):
    ax = plt.subplot(5,3,i+1)
    sns.boxplot(x = j, data = df)
plt.tight_layout()
plt.show()

final_cols = df.nunique()[df.nunique().sort_values(ascending=True) > 5].index.to_list()
final_cols

for col in final_cols:
    od = outlier_detector(df[col])
    print(f'{col} outliers: \n {od}')

"""#### Replacing outlier values with median value of respective features"""

for col in cols:
    od = outlier_detector(df[col])
    if len(od) > 0:
        fixed_val = np.median(df[col])
        od_in_col = [val for val in od if val in df[col].values]
        mask = df[col].isin(od_in_col)
        df.loc[mask,col] = fixed_val

for col in final_cols:
    od = outlier_detector(df[col])
    print(f'{col} outliers: \n {od}')

"""### Checking for Correlation & Feature Importance"""

plt.figure(figsize=(15, 10))
sns.heatmap(df.corr(), annot= True, fmt = '.2f')

"""> NO feature shows inherently high correlation with each other. Thus, we can proceed with the data as is"""

extc = ExtraTreesClassifier()
extc.fit(df.drop(['target'],axis='columns'),df['target'])

pd.Series(extc.feature_importances_, index=df.drop(['target'],axis='columns').columns).sort_values(ascending=False)

"""## Model Selection

### Train & Test Data Setup
"""

X = df.drop(['target'], axis='columns')
y = df['target']

X_train,X_test,y_train,y_test = train_test_split(X,y, test_size= 0.25, random_state=1)

print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)

"""#### Setting up ROC curve function for subsequent plotting of AUC"""

def plot_roc_curve(fpr, tpr):
  plt.plot(fpr, tpr, color = 'orange', label = 'ROC')
  plt.plot([0,1], [0,1], color = 'darkblue', linestyle = '--')
  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')
  plt.title('Receiver Operating Characteristic (ROC) Curve')
  plt.legend()
  plt.show()

"""### Support Vector Classifier"""

m1="SVC"
svc = SVC(probability=True)

svc.fit(X_train,y_train)

y_pred = svc.predict(X_test)
acc_svc = accuracy_score(y_test,y_pred) * 100

y_true = y_test
y_score = svc.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score)
print(f'Area Under Curve: {metrics.roc_auc_score(y_true, y_score)}')
optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]
print("Optimal threshold: ", optimal_threshold)
plot_roc_curve(fpr, tpr)

print(f'Accuracy: {accuracy_score(y_test,y_pred) * 100: .3f}% \n Classification report:\n {classification_report(y_test, y_pred, zero_division = 0)} \n Confusion Matrix:\n {confusion_matrix(y_test,y_pred)}')

"""### Gaussian Naive Bayes"""

m2 = "Gaussian NB"
gnb = GaussianNB()
gnb.fit(X,y)

y_pred = gnb.predict(X_test)
acc_gnb = accuracy_score(y_test,y_pred) * 100

y_true = y_test
y_score = gnb.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score)
print(f'Area Under Curve: {metrics.roc_auc_score(y_true, y_score)}')
optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]
print("Optimal threshold: ", optimal_threshold)
plot_roc_curve(fpr, tpr)

print(f'Accuracy: {accuracy_score(y_test,y_pred) * 100: .3f}% \n Classification report:\n {classification_report(y_test, y_pred, zero_division = 0)} \n Confusion Matrix:\n {confusion_matrix(y_test,y_pred)}')

"""### Logistic Regression"""

m3 = "LogReg"
logreg = LogisticRegression(max_iter=2000)

logreg.fit(X_train,y_train)

y_pred = logreg.predict(X_test)
acc_logreg = accuracy_score(y_test,y_pred) * 100

y_true = y_test
y_score = logreg.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score)
print(f'Area Under Curve: {metrics.roc_auc_score(y_true, y_score)}')
optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]
print("Optimal threshold: ", optimal_threshold)
plot_roc_curve(fpr, tpr)

print(f'Accuracy: {accuracy_score(y_test,y_pred) * 100: .3f}% \n Classification report:\n {classification_report(y_test, y_pred, zero_division = 0)} \n Confusion Matrix:\n {confusion_matrix(y_test,y_pred)}')

"""### KNeighborsClassifier"""

m4 = "KN Classifier"
knc = KNeighborsClassifier()

knc.fit(X_train,y_train)

y_pred = knc.predict(X_test)
acc_knc = accuracy_score(y_test,y_pred) * 100

y_true = y_test
y_score = knc.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score)
print(f'Area Under Curve: {metrics.roc_auc_score(y_true, y_score)}')
optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]
print("Optimal threshold: ", optimal_threshold)
plot_roc_curve(fpr, tpr)

print(f'Accuracy: {accuracy_score(y_test,y_pred) * 100: .3f}% \n Classification report:\n {classification_report(y_test, y_pred, zero_division = 0)} \n Confusion Matrix:\n {confusion_matrix(y_test,y_pred)}')

"""### Random Forest"""

m5 = "Random Forest"
rf = RandomForestClassifier(n_estimators=30,criterion='entropy',max_depth=4,min_samples_split=7,n_jobs=-1)

rf.fit(X_train,y_train)

y_pred = rf.predict(X_test)
acc_rf = accuracy_score(y_test,y_pred) * 100

y_true = y_test
y_score = rf.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score)
print(f'Area Under Curve: {metrics.roc_auc_score(y_true, y_score)}')
optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]
print("Optimal threshold: ", optimal_threshold)
plot_roc_curve(fpr, tpr)

print(f'Accuracy: {accuracy_score(y_test,y_pred) * 100: .3f}% \n Classification report:\n {classification_report(y_test, y_pred, zero_division = 0)} \n Confusion Matrix:\n {confusion_matrix(y_test,y_pred)}')

"""### Gradient Boost"""

m6 = "Gradient Boost"
grb = GradientBoostingClassifier(loss='log_loss',learning_rate=0.01,n_estimators=30,max_depth=4,subsample=0.8)

grb.fit(X_train,y_train)

y_pred = grb.predict(X_test)
acc_grb = accuracy_score(y_test,y_pred) * 100

y_true = y_test
y_score = grb.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score)
print(f'Area Under Curve: {metrics.roc_auc_score(y_true, y_score)}')
optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]
print("Optimal threshold: ", optimal_threshold)
plot_roc_curve(fpr, tpr)

print(f'Accuracy: {accuracy_score(y_test,y_pred) * 100: .3f}% \n Classification report:\n {classification_report(y_test, y_pred, zero_division = 0)} \n Confusion Matrix:\n {confusion_matrix(y_test,y_pred)}')

"""### XG Boost"""

m7 = "XGBoost"
xgb = XGBClassifier(learning_rate=0.01,n_estimators=25,max_depth=10,gamma=0.7,booster='dart',
                    reg_lambda=1,subsample=0.8)

xgb.fit(X_train,y_train)

y_pred = xgb.predict(X_test)
acc_xgb = accuracy_score(y_test,y_pred) * 100

y_true = y_test
y_score = xgb.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score)
print(f'Area Under Curve: {metrics.roc_auc_score(y_true, y_score)}')
optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]
print("Optimal threshold: ", optimal_threshold)
plot_roc_curve(fpr, tpr)

print(f'Accuracy: {accuracy_score(y_test,y_pred) * 100: .3f}% \n Classification report:\n {classification_report(y_test, y_pred, zero_division = 0)} \n Confusion Matrix:\n {confusion_matrix(y_test,y_pred)}')

results = pd.DataFrame({'Models': [m1, m2, m3, m4, m5, m6, m7],
                     'Accuracy': [acc_svc, acc_gnb, acc_logreg, acc_knc, acc_rf, acc_grb, acc_xgb]})

results

"""#### Conclusions:

1. `SVC`, `Gaussian NB` and `K-Neighbors Classifier` have performed poorly.(Accuracy < 80%)

2. `Logistic Regression`, `Random Forest`, `Gradient Boost` and `Extreme Gradient Boost` have shown to be potentially better models. Hence, we will proceed with the following 4 for *Model Optimisation*

## Model Optimisation

### Hyperparameter Tuning
"""

grid_logreg = {
    'max_iter': [5000,6000,8000],
    'C' : np.logspace(-4,1,4),
    'solver' : ['liblinear', 'lbfgs', 'saga', 'newton-cg']
}

grid_rf = {
    'criterion': ['entropy','gini','log_loss'],
    'max_depth': [4,5],
    'n_estimators': [30,31],
    'max_leaf_nodes' : range(2,31,5),
    'min_samples_split': [10,12,13]
}

grid_grb = {
    'loss': ['log_loss','exponential'],
    'learning_rate': [0.0168,0.0174],
    'max_depth': [4,5],
    'min_samples_split': [10,12,13],
    'n_estimators':[32,33,34],
    'subsample' : [0.78,0.76,0.74],
}

grid_xgb = {
    'learning_rate': [0.017,0.019],
    'n_estimators': [30,35,38],
    'max_depth': [8,10],
    'gamma': [0.75, 0.73],
    'booster': ['dart'],
    'reg_lambda': [0.86],
    'subsample': [0.85,0.86],
    'colsample_bylevel': [0.5,0.6],
    'colsample_bynode' : [0.5,0.6]
}

ht_logreg = LogisticRegression()
ht_rf = RandomForestClassifier()
ht_grb = GradientBoostingClassifier()
ht_xgb = XGBClassifier()

gs_logreg = GridSearchCV(estimator = ht_logreg,
                          param_grid = grid_logreg,
                          cv=10,
                          verbose = 1,
                          n_jobs = -1)

gs_rf = GridSearchCV(estimator = ht_rf,
                          param_grid = grid_rf,
                          cv=3,
                          verbose = 1,
                          n_jobs = -1)

gs_grb = GridSearchCV(estimator = ht_grb,
                          param_grid = grid_grb,
                          cv=3,
                          verbose = 1,
                          n_jobs = -1)

gs_xgb = GridSearchCV(estimator = ht_xgb,
                          param_grid = grid_xgb,
                          cv=3,
                          verbose = 1,
                          n_jobs = -1)

gs_logreg.fit(X_train,y_train)

gs_rf.fit(X_train,y_train)

gs_grb.fit(X_train,y_train)

gs_xgb.fit(X_train,y_train)

logreg_bs = gs_logreg.best_score_
grb_bs = gs_grb.best_score_
rf_bs = gs_rf.best_score_
xgb_bs = gs_xgb.best_score_

final_score = pd.DataFrame({'Models' : [m3,m5,m6,m7],
                       'Scores': [logreg_bs*100,grb_bs*100,rf_bs*100,xgb_bs*100],
                       'Training Accuracy': [accuracy_score(y_train,gs_logreg.predict(X_train))*100,
                                             accuracy_score(y_train,gs_rf.predict(X_train))*100,
                                             accuracy_score(y_train,gs_grb.predict(X_train))*100,
                                             accuracy_score(y_train,gs_xgb.predict(X_train))*100],
                       'Test Accuracy' : [accuracy_score(y_test,gs_logreg.predict(X_test))*100,
                                          accuracy_score(y_test,gs_rf.predict(X_test))*100,
                                          accuracy_score(y_test,gs_grb.predict(X_test))*100,
                                          accuracy_score(y_test,gs_xgb.predict(X_test))*100]})

final_score

"""### Conclusions:

1. `Logistic Regression` and `Random Forest`, despite optimisation, have not been performed adequately with Testing Data.

2. `XGBoost` and `Gradient Boost` have performed equally well with Test Data.

3. `Gradient Boost` may be marginally more *overfitted* than the `XGBoost` model. Additionally, the latter has better *validation score* than the former.

Therefore, the `XGBoost` will be considered as the best model for the data.

## Fitting the best model to the Data
"""

bp = gs_xgb.best_params_
bp

model = XGBClassifier(booster = bp['booster'],
                      colsample_bylevel = bp['colsample_bylevel'],
                      colsample_bynode = bp['colsample_bynode'],
                      gamma = bp['gamma'],
                      learning_rate = bp['learning_rate'],
                      max_depth = bp['max_depth'],
                      n_estimators = bp['n_estimators'],
                      reg_lambda = bp['reg_lambda'],
                      subsample = bp['subsample'])
model.fit(X_train,y_train)

y_pred = model.predict(X_test)

y_true = y_test
y_score = model.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score)
print(f'Area Under Curve: {metrics.roc_auc_score(y_true, y_score)}')
optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]
print("Optimal threshold: ", optimal_threshold)
plot_roc_curve(fpr, tpr)

print(f'Accuracy: {accuracy_score(y_test,y_pred) * 100: .3f}% \n Classification report:\n {classification_report(y_test, y_pred, zero_division = 0)} \n Confusion Matrix:\n {confusion_matrix(y_test,y_pred)}')

plt.figure(figsize=(20,30), dpi=200)
plot_tree(model=model, booster = model.get_booster())
plt.show()

"""***********************************************************************"""